{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about data:\n",
    "\n",
    "                     ->We have the amazon reviews dataset from kaggle\n",
    "                     \n",
    "                     ->Reviews are given for the product\n",
    "                     \n",
    "                     ->The features of the data were:\n",
    "                     \n",
    "                           Id\n",
    "                           \n",
    "                           ProductId- unique identifier for the product\n",
    "                           \n",
    "                           UserId- unqiue identifier for the user\n",
    "                           \n",
    "                           ProfileName\n",
    "                           \n",
    "                           HelpfullnessNumerator- number of users who found the review helpful\n",
    "                           \n",
    "                           HelpfulnessDenominator- number of users who indicated whether they found the review \n",
    "                                                   helpful or not\n",
    "                           \n",
    "                           Score-rating between 1 and 5\n",
    "                           \n",
    "                           Time-timestamp for the review\n",
    "                           \n",
    "                           Summary- brief summary of the review\n",
    "                           \n",
    "                           Text- text of the review\n",
    "                       \n",
    "                     -> Based on the score of the review we review we classify them into positive and negative\n",
    "                     \n",
    "                     Number of reviews: 568,454\n",
    "\n",
    "                     \n",
    "                    \n",
    "                     \n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "    -> Cleaning the dataset by classifying them into positive and negative reviews based on the \n",
    "       rating provided and removing the duplicates\n",
    "\n",
    "    -> Converting the text data to vectors by using Bag of words,Tfidf,word2vec,Average word2vec\n",
    "\n",
    "    -> Implementing Support Vector Machines with kernel as RBF\n",
    "    \n",
    "    -> Implementing Linear Kernel SVM\n",
    "    \n",
    "    -> Implementing nu-SVM\n",
    "    \n",
    "    -> Using Grid Search and Random Search th determine the best hyper parameters\n",
    "    \n",
    "    -> In RBF-SVM the hyper parameters are \"C\" and \"GAMMA\"\n",
    "    \n",
    "    -> To check the performance with different \"C\" and \"GAMMA\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Establishing the connection and loading the data\n",
    "\n",
    "-> Shape of the data\n",
    "\n",
    "-> Dimensionality of the data\n",
    "\n",
    "-> Attributes of the data\n",
    "\n",
    "-> Sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "connection = sqlite3.connect(\"database.sqlite\")\n",
    "data = pd.read_sql_query(\"SELECT * FROM Reviews WHERE Score != 3\",connection)\n",
    "print(data.shape)\n",
    "print(data.ndim)\n",
    "print(data.columns)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-processing:\n",
    "      \n",
    "    -> Cleaning the data\n",
    "    \n",
    "    -> Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  positive  1303862400   \n",
       "1                     0                       0  negative  1346976000   \n",
       "2                     1                       1  positive  1219017600   \n",
       "3                     3                       3  negative  1307923200   \n",
       "4                     0                       0  positive  1350777600   \n",
       "5                     0                       0  positive  1342051200   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
       "5             Nice Taffy  I got a wild hair for taffy and ordered this f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(n):\n",
    "    if n>3:\n",
    "        return 'positive'\n",
    "    return 'negative'\n",
    "rating = data['Score']    \n",
    "rating = rating.map(score)  \n",
    "data['Score'] = rating    \n",
    "data.head(6)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_data = data.sort_values('ProductId',axis=0,ascending=True,inplace=False,kind='quicksort',na_position='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = sorting_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep='first',inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the cleaned data:\n",
    "\n",
    "    -> Shape of the data\n",
    "\n",
    "    -> Dimensionality of the data\n",
    "\n",
    "    -> Attributes of the data\n",
    "\n",
    "    -> Sample of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364173, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "            Id   ProductId          UserId                  ProfileName  \\\n",
      "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
      "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
      "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
      "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
      "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "138706                     0                       0  positive   939340800   \n",
      "138688                     1                       1  positive  1194739200   \n",
      "138689                     1                       1  positive  1191456000   \n",
      "138690                     1                       1  positive  1076025600   \n",
      "138691                     3                       4  positive  1018396800   \n",
      "\n",
      "                                           Summary  \\\n",
      "138706                   EVERY book is educational   \n",
      "138688  Love the book, miss the hard cover version   \n",
      "138689               chicken soup with rice months   \n",
      "138690      a good swingy rhythm for reading aloud   \n",
      "138691             A great way to learn the months   \n",
      "\n",
      "                                                     Text  \n",
      "138706  this witty little book makes my son laugh at l...  \n",
      "138688  I grew up reading these Sendak books, and watc...  \n",
      "138689  This is a fun way for children to learn their ...  \n",
      "138690  This is a great little book to read aloud- it ...  \n",
      "138691  This is a book of poetry about the months of t...  \n"
     ]
    }
   ],
   "source": [
    "print(cleaned_data.shape)\n",
    "print(cleaned_data.ndim)\n",
    "print(cleaned_data.columns)\n",
    "print(cleaned_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind about the performance capability of the box and time efficiency here i am taking the subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = cleaned_data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the sampled data:\n",
    "\n",
    "    -> Shape of the data\n",
    "\n",
    "    -> Dimensionality of the data\n",
    "\n",
    "    -> Attributes if the data\n",
    "\n",
    "    -> Sample of modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "            Id   ProductId          UserId                 ProfileName  \\\n",
      "255735  277245  B000VK8AVK  A1HLYNGUBXXW9S    Maureen in WA \"maureeng\"   \n",
      "173730  188447  B0051ZCRGY  A3L6O1NV34AJ2J  Richard Odato \"Slingboxer\"   \n",
      "282621  306193  B000JSM344  A3E5D99WX49BK7               Michelle Cohn   \n",
      "16096    17583  B0000GH6UQ  A18ZDBQ8LUNVO6           Jessica McCormick   \n",
      "477841  516720  B007WTQAKQ  A2YAAF9BCQ4AJC              Leigh Somebody   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "255735                    16                      17  positive  1215561600   \n",
      "173730                     0                       0  positive  1345334400   \n",
      "282621                     3                       5  positive  1199750400   \n",
      "16096                      0                       0  positive  1318377600   \n",
      "477841                     0                       0  positive  1337904000   \n",
      "\n",
      "                            Summary  \\\n",
      "255735             Excellent Chips!   \n",
      "173730  Our Cocker LOVES Pegetables   \n",
      "282621           Thank you so much!   \n",
      "16096          So long, Swiss Miss!   \n",
      "477841          Surprisingly Works!   \n",
      "\n",
      "                                                     Text  \n",
      "255735  These chips are really, really good.  I don't ...  \n",
      "173730  Our Cocker LOVES Pegetables!  She seems to rea...  \n",
      "282621  I use to be able to buy this in town and when ...  \n",
      "16096   A couple years ago, my husband pointed this co...  \n",
      "477841  Just on a whim, I thought I'd try this and it ...  \n"
     ]
    }
   ],
   "source": [
    "print(sample_data.shape)\n",
    "print(sample_data.ndim)\n",
    "print(sample_data.columns)\n",
    "print(sample_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM WITH RBF KERNEL:\n",
    "\n",
    "BAG OF WORDS:\n",
    "    \n",
    "    TIME BASED SPLITTING OF DATA:\n",
    "    \n",
    "         -> Implementing Support Vector Classifier with \"RBF\" as kernel\n",
    "        \n",
    "         -> Using both Grid Search and Random Search to determine the best hyper parameters\n",
    "            \n",
    "         -> To check performance measure with different hyper parameter values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = sample_data.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "cv_data_vect = count_vectorizer.fit_transform(cv_data['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sample_data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 61485)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = cv_data_vect[0:70000]\n",
    "xtest  = cv_data_vect[70000:]\n",
    "ytrain = score[0:70000]\n",
    "ytest  = score[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 61485)\n",
      "(30000, 61485)\n",
      "(70000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS: GRID SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf'], 'C':[0.01,0.1,1],'gamma':[0.01,0.1,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['rbf'], 'C': [0.01, 0.1, 1], 'gamma': [0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(classifier,param_grid=parameters,scoring='accuracy')\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=1,gamma=1,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=0.1,gamma=1,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=0.1,gamma=0.1,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=0.1,gamma=0.01,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=0.01,gamma=1,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS: RANDOM SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': scipy.stats.randint.rvs(1,5,size=5), 'gamma': scipy.stats.randint.rvs(1,5,size=5),'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "model = RandomizedSearchCV(classifier,param_distributions=parameters,scoring='accuracy',cv=5,n_iter=5,n_jobs=-1)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'C': array([2, 2, 3, 3, 4]), 'gamma': array([3, 4, 3, 2, 4]), 'kernel': ['rbf']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424666666666667\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=3,gamma=2,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424666666666667\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=2,gamma=2,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424666666666667\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=1,gamma=2,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8424666666666667\n"
     ]
    }
   ],
   "source": [
    "classif = SVC(C=3,gamma=1,kernel='rbf')\n",
    "classif.fit(xtrain,ytrain)\n",
    "pred = classif.predict(xtest)\n",
    "acc = accuracy_score(ytest,pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    -> BAG OF WORDS:\n",
    "        \n",
    "        -> By using Grid Search with \"RBF\" as kernel the best values of hyper parameters were C = 1 and gamma = 3\n",
    "        \n",
    "        -> By using Random search with \"RBF\" as kernel the best values of hyper parameters were C = 3 and gamma = 2\n",
    "        \n",
    "        -> The accurancy by grid search is 84.19\n",
    "        \n",
    "        -> The accurancy of random search is 84.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM WITH LINEAR KERNEL:\n",
    "\n",
    "TFIDF:\n",
    "    \n",
    "    TIME BASED SPLITTING OF DATA:\n",
    "    \n",
    "         -> Implementing Support Vector Classifier with Linear kernel\n",
    "        \n",
    "         -> Using both Grid Search and Random Search to determine the best hyper parameters\n",
    "            \n",
    "         -> To check performance measure with different hyper parameter values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_data = sample_data.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_vect_data = tfid.fit_transform(tfid_data['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1283627)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfid_vect_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tfid_vect_data[0:10000]\n",
    "score = tfid_data['Score'][0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = sample[0:7000]\n",
    "xtest = sample[7000:]\n",
    "ytrain = score[0:7000]\n",
    "ytest = score[7000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 1283627)\n",
      "(7000,)\n",
      "(3000, 1283627)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF: GRID SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(loss=\"hinge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':[0.01,0.1,1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': [0.01, 0.1, 1, 10, 100]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=0)\n",
      "0.8936666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(classifier,param_grid=parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.0001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.8936666666666667\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 0.0001)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8936666666666667\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C = 0.01)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF: RANDOM SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([8, 1, 9, 4, 5])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': scipy.stats.randint.rvs(1,10,size=5)}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=8, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "classifier = LinearSVC(loss='hinge')\n",
    "model = RandomizedSearchCV(classifier,param_distributions=parameters,scoring='accuracy',cv=5,n_iter=5,n_jobs=-1)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=8, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C = 8)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.14"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C = 0.0001, gamma= 0.01)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.14"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    TFIDF:\n",
    "    \n",
    "    -> By using Grid Search with Linear SVM the best values of hyper parameters were C = 0.001 \n",
    "\n",
    "    -> By using Random search with Linear SVM the best values of hyper parameters were C = 8\n",
    "\n",
    "    -> The accurancy by grid search is 89.36\n",
    "\n",
    "    -> The accurancy of random search is 87.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD2VEC:\n",
    "\n",
    "        CONSTRUCTING VECTOR REPRESENTATION OF EACH IN THE DATA BY USING WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Importing the required libraries\n",
    "\n",
    "-> Functions to clean the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanhtml(sentence):\n",
    "    clean = re.compile(\"<.*?>\")\n",
    "    cleantext = re.sub(clean,\" \",sentence)\n",
    "    return cleantext\n",
    "def cleanpunct(sentence):\n",
    "    cleanr = re.sub(r\"[?|!|\\|'|#|.|,|)|(|/]\",r' ',sentence)\n",
    "    return cleanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_w2vec = sample_data.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the sorted data:\n",
    "\n",
    "    -> Shape of the data\n",
    "\n",
    "    -> Dimensionality of the data\n",
    "\n",
    "    -> Attributes if the data\n",
    "\n",
    "    -> Sample of modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "            Id   ProductId          UserId               ProfileName  \\\n",
      "138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
      "417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
      "417883  451903  B00004CXX9  A2DEE7F9XKP3ZR                    jerome   \n",
      "1146      1245  B00002Z754  A29Z5PI9BW2PU3                    Robbie   \n",
      "346115  374421  B00004CI84  A1FJOY14X3MUHE             Justin Howard   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
      "138683                     2                       2  positive  940809600   \n",
      "417838                     0                       0  positive  946857600   \n",
      "417883                     0                       1  positive  959990400   \n",
      "1146                       7                       7  positive  961718400   \n",
      "346115                     2                       2  positive  966297600   \n",
      "\n",
      "                                                  Summary  \\\n",
      "138683  This whole series is great way to spend time w...   \n",
      "417838                                         FANTASTIC!   \n",
      "417883                                           Research   \n",
      "1146                                        Great Product   \n",
      "346115  A fresh, original film from master storyteller...   \n",
      "\n",
      "                                                     Text  \n",
      "138683  I can remember seeing the show when it aired o...  \n",
      "417838  Beetlejuice is an excellent and funny movie. K...  \n",
      "417883  I'm getting crazy.<p>Is it really impossible t...  \n",
      "1146    This was a really good idea and the final prod...  \n",
      "346115  This is such a great film, I don't even know h...  \n"
     ]
    }
   ],
   "source": [
    "print(sorted_w2vec.shape)\n",
    "print(sorted_w2vec.ndim)\n",
    "print(sorted_w2vec.columns)\n",
    "print(sorted_w2vec.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "sentences_list=[]\n",
    "for sent in sorted_w2vec['Text'].values:\n",
    "    filtered_sentences = []\n",
    "    sent = cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleanedwords in cleanpunct(w).split():\n",
    "            if(cleanedwords.isalpha()):\n",
    "                filtered_sentences.append(cleanedwords.lower())\n",
    "    sentences_list.append(filtered_sentences)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_list))\n",
    "print(type(sentences_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = gensim.models.Word2Vec(sentences_list,min_count=4,size=200,workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Most similar word\n",
    "\n",
    "-> Similarity between the words\n",
    "\n",
    "-> Dimensionality representation of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('foil', 0.3661514222621918), ('printed', 0.3577941656112671), ('marked', 0.3473374545574188), ('metal', 0.34421518445014954), ('contents', 0.33536863327026367), ('loosely', 0.33394986391067505), ('divided', 0.3335522413253784), ('each', 0.3309260606765747), ('torn', 0.3271692097187042), ('this', 0.326387882232666)]\n",
      "0.15672317384225404\n",
      "[ 7.46376738e-02 -3.91671211e-02 -9.74655803e-03  1.17327280e-01\n",
      "  4.30680700e-02  1.42935008e-01  1.69160645e-02 -9.99073833e-02\n",
      " -8.94245226e-03  7.31556639e-02  2.71437708e-02  8.49297866e-02\n",
      " -3.79108302e-02 -4.03551161e-02  1.79700971e-01 -8.83629546e-02\n",
      "  6.21749647e-02  1.70396626e-01 -9.88507271e-02 -3.23529937e-03\n",
      " -1.54427374e-02 -3.88860442e-02  2.32633371e-02 -8.95061940e-02\n",
      " -5.09793237e-02 -8.53051022e-02 -2.16724798e-01 -8.22060779e-02\n",
      "  1.60596505e-01  2.38274857e-01  6.77032471e-02  2.92483121e-02\n",
      " -1.52913973e-01 -8.54681283e-02  3.81469503e-02  1.63954377e-01\n",
      " -1.04502574e-01 -2.37784889e-02  2.73989085e-02  1.55599207e-01\n",
      " -2.77195079e-03  1.89030655e-02  4.68748361e-02  2.11649723e-02\n",
      "  3.29707451e-02 -9.35959592e-02  1.53364509e-01  8.30018222e-02\n",
      "  1.56344399e-01  2.09414542e-01 -1.09019009e-02 -8.27383846e-02\n",
      " -1.52124390e-01  2.04615861e-01  1.84260547e-01  1.78548589e-01\n",
      "  1.75115541e-02  1.01964595e-02  2.85195210e-03  8.62797499e-02\n",
      "  1.57599911e-01 -6.92393258e-02  2.03184187e-01  3.93796858e-04\n",
      "  2.88663972e-02  2.57268101e-01 -9.62323770e-02 -1.19149141e-01\n",
      "  1.88405007e-01  1.53981045e-01  9.49712843e-02 -7.32565746e-02\n",
      " -4.71446812e-02  6.39423653e-02 -2.86645442e-02 -7.28903562e-02\n",
      "  2.74329204e-02  1.42536268e-01  3.79656479e-02 -2.90902182e-02\n",
      " -7.72973225e-02 -3.79364908e-01  1.44835740e-01  2.89077967e-01\n",
      "  1.83294430e-01 -8.90121460e-02 -1.18728027e-01 -3.65421809e-02\n",
      "  1.50683001e-01  5.75584024e-02  6.35507181e-02 -6.93864524e-02\n",
      " -7.18736127e-02  4.85871844e-02 -7.92968273e-02 -7.60947764e-02\n",
      "  1.75751209e-01  1.56454127e-02  4.42015640e-02  1.00735486e-01\n",
      "  2.36615837e-02  1.41660385e-02  1.73439924e-03  3.85778993e-02\n",
      "  1.47505954e-01 -5.57372011e-02  1.99366614e-01  1.77332927e-02\n",
      "  1.39017720e-02  5.20809088e-03 -3.51771899e-02 -1.91033900e-01\n",
      "  1.33832600e-02 -9.94292200e-02  3.76986302e-02  9.38725099e-03\n",
      "  2.85761002e-02 -4.29738127e-02  7.43370620e-04 -2.47689307e-01\n",
      "  8.02268460e-02  2.27401834e-02  2.83477485e-01  1.24741815e-01\n",
      "  5.13344586e-01 -1.04342841e-01  9.24930423e-02  1.10017419e-01\n",
      " -3.39711964e-01 -3.63127738e-02 -6.21374734e-02 -9.39397067e-02\n",
      " -4.27645631e-02  4.19991016e-02  1.27547383e-01 -1.16916738e-01\n",
      "  1.53501838e-01 -1.62372038e-01 -7.45334476e-02 -1.64226457e-01\n",
      "  1.24249734e-01  2.45201990e-01 -2.82593012e-01 -2.52310280e-02\n",
      "  5.01009524e-02  1.28962547e-01  3.16310897e-02  8.67929310e-02\n",
      "  3.72633100e-01  2.05868393e-01 -1.23229228e-01 -2.31928229e-01\n",
      "  1.47817180e-01 -1.47775665e-01  7.49128535e-02  9.20652598e-02\n",
      "  1.92804068e-01 -2.17391551e-01 -6.01991778e-03  8.68222117e-02\n",
      "  4.75134291e-02 -1.32257745e-01 -2.10440829e-02 -1.56973869e-01\n",
      " -6.19931072e-02  1.25609227e-02 -1.23218983e-01  2.53714114e-01\n",
      "  1.86279014e-01  2.62722641e-01  1.78902242e-02 -1.56033605e-01\n",
      "  9.97112147e-05  8.21634233e-02 -1.82665229e-01  5.08229099e-02\n",
      " -4.72846329e-02 -1.46754622e-01  5.48403300e-02  1.43918321e-01\n",
      "  1.39083862e-01  2.09148712e-02 -8.22087154e-02 -6.02755025e-02\n",
      "  6.76847994e-02 -1.21093611e-03 -9.16820243e-02  8.49751532e-02\n",
      " -1.14586517e-01  1.89506263e-01 -1.04682297e-02 -5.79984039e-02\n",
      "  2.53672209e-02  1.11608185e-01 -9.44144577e-02 -3.44396085e-02\n",
      "  6.49087224e-03  1.61137000e-01 -1.84098765e-01 -6.27396954e-03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(w2vmodel.most_similar(\"the\"))\n",
    "print(w2vmodel.similarity(\"this\",'these'))\n",
    "print(w2vmodel.wv['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    -> We have constructed the vector representation of each word\n",
    "    \n",
    "    -> Using this model to construct vector representation of each sentence in average word2vec\n",
    "    \n",
    "    -> Each word in the model is of 200-dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu - Support Vector Classification\n",
    "\n",
    "AVERAGE WORD2VEC:\n",
    "    \n",
    "    TIME BASED SPLITTING OF DATA:\n",
    "    \n",
    "         -> Implementing Nu Support Vector Classifier\n",
    "        \n",
    "         -> Using both Grid Search and Random Search to determine the best hyper parameters\n",
    "            \n",
    "         -> To check performance measure with different hyper parameter values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent_vectors = []\n",
    "for sent in sentences_list: \n",
    "    sent_vec = np.zeros(200) \n",
    "    cnt=0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = w2vmodel.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[88888]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors = np.nan_to_num(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vect = sent_vectors[0:10000]\n",
    "sample_score = sorted_w2vec['Score'][0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = sample_vect[0:7000]\n",
    "xtest  = sample_vect[7000:]\n",
    "ytrain = sample_score[0:7000]\n",
    "ytest = sample_score[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 200)\n",
      "(3000, 200)\n",
      "(7000,)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print((xtrain.shape))\n",
    "print((xtest.shape))\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC: GRID SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'nu':[0.1,0.2,0.15,0.05]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'nu': [0.1, 0.2, 0.15, 0.05]}, pre_dispatch='2*n_jobs',\n",
      "       refit=True, return_train_score='warn', scoring='accuracy',\n",
      "       verbose=0)\n",
      "0.916\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(classifier,param_grid=parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.1, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "0.9156666666666666\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC(nu=0.1)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.2, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "0.916\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC(nu=0.2)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.01, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC(nu=0.01)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC: RANDOM SEARCH TO FIND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nu': array([0.  , 0.25, 0.5 , 0.75, 1.  ])}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'nu': np.linspace(0.0,1,5)}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NuSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=4, n_jobs=1,\n",
       "          param_distributions={'nu': [0.1, 0.2, 0.15, 0.05]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomizedSearchCV(classifier,param_distributions=parameters,cv=5,n_iter=4)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(xtest)\n",
    "score = accuracy_score(ytest,pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.01, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC(nu=0.01)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
      "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "   max_iter=-1, nu=0.1, probability=False, random_state=None,\n",
      "   shrinking=True, tol=0.001, verbose=False)\n",
      "0.9156666666666666\n"
     ]
    }
   ],
   "source": [
    "model = NuSVC(nu=0.1)\n",
    "model.fit(xtrain,ytrain)\n",
    "pred = model.predict(xtest)\n",
    "score  = accuracy_score(ytest,pred)\n",
    "print(model)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    AVERAGE word2VEC:\n",
    "    \n",
    "    -> By using Grid Search with NuSVC the best values of hyper parameters were nu = 0.5 \n",
    "\n",
    "    -> By using Random search with NuSVC the best values of hyper parameters were nu = 0.5\n",
    "\n",
    "    -> The accurancy by grid search is 91.6\n",
    "\n",
    "    -> The accurancy of random search is 91.6\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "    \n",
    "    RBF SVM:\n",
    "        \n",
    "        BAG OF WORDS:\n",
    "            \n",
    "            -> Implemented RBF SVM with Grid Search and random Search\n",
    "            \n",
    "            -> By using Grid Search with \"RBF\" as kernel the best values of hyper parameters were C = 1 and gamma = 3\n",
    "\n",
    "            -> By using Random search with \"RBF\" as kernel the best values of hyper parameters were C = 3 and gamma= 2\n",
    "\n",
    "            -> The accurancy by grid search is 84.19\n",
    "\n",
    "            -> The accurancy of random search is 84.24\n",
    "            \n",
    "            -> Measured accuracy with differenct combinations of hyper parameters\n",
    "            \n",
    "    LINEAR SVM:\n",
    "        \n",
    "        TFIDF:\n",
    "            \n",
    "            -> Implemented Linear SVM with Grid Search and random Search\n",
    "                \n",
    "            -> By using Grid Search with Linear SVM the best values of hyper parameters were C = 0.001 \n",
    "\n",
    "            -> By using Random search with Linear SVM the best values of hyper parameters were C = 8\n",
    "\n",
    "            -> The accurancy by grid search is 89.36\n",
    "\n",
    "            -> The accurancy of random search is 87.14\n",
    "                \n",
    "            -> Measured accuracy with differenct combinations of hyper parameters\n",
    "                \n",
    "    NuSVM:\n",
    "        \n",
    "        AVERAGE WORD2VEC:\n",
    "            \n",
    "            -> Implemented Nu SVM with Grid Search and random Search\n",
    "            \n",
    "            -> By using Grid Search with NuSVC the best values of hyper parameters were nu = 0.5 \n",
    "\n",
    "            -> By using Random search with NuSVC the best values of hyper parameters were nu = 0.5\n",
    "\n",
    "            -> The accurancy by grid search is 91.6\n",
    "\n",
    "            -> The accurancy of random search is 91.6\n",
    "            \n",
    "            -> Measured accuracy with differenct combinations of hyper parameters\n",
    "                 \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
