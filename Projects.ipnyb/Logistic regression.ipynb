{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about data:\n",
    "\n",
    "                     ->We have the amazon reviews dataset from kaggle\n",
    "                     \n",
    "                     ->Reviews are given for the product\n",
    "                     \n",
    "                     ->The features of the data were:\n",
    "                     \n",
    "                           Id\n",
    "                           \n",
    "                           ProductId- unique identifier for the product\n",
    "                           \n",
    "                           UserId- unqiue identifier for the user\n",
    "                           \n",
    "                           ProfileName\n",
    "                           \n",
    "                           HelpfullnessNumerator- number of users who found the review helpful\n",
    "                           \n",
    "                           HelpfulnessDenominator- number of users who indicated whether they found the review \n",
    "                                                   helpful or not\n",
    "                           \n",
    "                           Score-rating between 1 and 5\n",
    "                           \n",
    "                           Time-timestamp for the review\n",
    "                           \n",
    "                           Summary- brief summary of the review\n",
    "                           \n",
    "                           Text- text of the review\n",
    "                       \n",
    "                     -> Based on the score of the review we review we classify them into positive and negative\n",
    "                     \n",
    "                     Number of reviews: 568,454\n",
    "\n",
    "                     \n",
    "                    \n",
    "                     \n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "    \n",
    "    -> Cleaning the dataset by classifying them into positive and negative reviews based on the \n",
    "        rating provided and removing the duplicates\n",
    "\n",
    "    -> Converting the text data to vectors by using Bag of words,Tfidf,word2vec,Average word2vec\n",
    "    \n",
    "    -> Applying logistic regression to determine the best lambda\n",
    "    \n",
    "    -> Using grid search and random search to determine the best lambda\n",
    "    \n",
    "    -> Using both L1 and L2 regularizations and checking the sparsity with different values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mp\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
    "import sqlite3\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import cross_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "->loading the data and information about the data\n",
    "\n",
    "-> Shape of the data\n",
    "\n",
    "-> Dimensionality of the data\n",
    "\n",
    "-> Attributes if the data\n",
    "\n",
    "-> Sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
     ]
    }
   ],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")\n",
    "data = pd.read_sql_query(\"SELECT * FROM Reviews WHERE Score != 3\",con)\n",
    "print(data.shape)\n",
    "print(data.ndim)\n",
    "print(data.columns)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PRE-PROCESSING:\n",
    "    \n",
    "    -> Classifying the reviews into positive and negative based on the score for the review\n",
    "    \n",
    "    -> Considering reviews with score 3 as neutral and 1,2 as negative and 4,5 as positive\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  positive  1303862400   \n",
       "1                     0                       0  negative  1346976000   \n",
       "2                     1                       1  positive  1219017600   \n",
       "3                     3                       3  negative  1307923200   \n",
       "4                     0                       0  positive  1350777600   \n",
       "5                     0                       0  positive  1342051200   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
       "5             Nice Taffy  I got a wild hair for taffy and ordered this f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change(n):\n",
    "    if n>3:\n",
    "        return 'positive'\n",
    "    return 'negative'\n",
    "\n",
    "rating = data['Score']    \n",
    "\n",
    "rating = rating.map(change)  \n",
    "\n",
    "data['Score'] = rating    \n",
    "\n",
    "data.head(6)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PRE-PROCESSING:\n",
    "    \n",
    "    Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId         UserId      ProfileName  HelpfulnessNumerator  \\\n",
      "0   78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
      "1  138317  B000HDOPYC  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
      "2  138277  B000HDOPYM  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
      "3   73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
      "4  155049  B000PAQ75C  AR5J8UI46CURR  Geetha Krishnan                     2   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time  \\\n",
      "0                       2      5  1199577600   \n",
      "1                       2      5  1199577600   \n",
      "2                       2      5  1199577600   \n",
      "3                       2      5  1199577600   \n",
      "4                       2      5  1199577600   \n",
      "\n",
      "                             Summary  \\\n",
      "0  LOACKER QUADRATINI VANILLA WAFERS   \n",
      "1  LOACKER QUADRATINI VANILLA WAFERS   \n",
      "2  LOACKER QUADRATINI VANILLA WAFERS   \n",
      "3  LOACKER QUADRATINI VANILLA WAFERS   \n",
      "4  LOACKER QUADRATINI VANILLA WAFERS   \n",
      "\n",
      "                                                Text  \n",
      "0  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
      "1  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
      "2  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
      "3  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
      "4  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n"
     ]
    }
   ],
   "source": [
    "user = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE UserId= \"AR5J8UI46CURR\" ORDER BY ProductId \"\"\",con)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    -> Here we can see that for the same time span we got five reviews, practically which is not possible\n",
    "    \n",
    "    ->This happened because when the user given review for a product it is applied to all the flavors of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorteddata = data.sort_values('ProductId',axis=0,ascending=True,inplace=False,kind='quicksort',na_position='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata = sorteddata.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep='first',inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the modified data:\n",
    "\n",
    "    -> Shape of the data\n",
    "\n",
    "    -> Dimensionality of the data\n",
    "\n",
    "    -> Attributes if the data\n",
    "\n",
    "    -> Sample of modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364173, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "            Id   ProductId          UserId                  ProfileName  \\\n",
      "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
      "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
      "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
      "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
      "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
      "138706                     0                       0  positive   939340800   \n",
      "138688                     1                       1  positive  1194739200   \n",
      "138689                     1                       1  positive  1191456000   \n",
      "138690                     1                       1  positive  1076025600   \n",
      "138691                     3                       4  positive  1018396800   \n",
      "\n",
      "                                           Summary  \\\n",
      "138706                   EVERY book is educational   \n",
      "138688  Love the book, miss the hard cover version   \n",
      "138689               chicken soup with rice months   \n",
      "138690      a good swingy rhythm for reading aloud   \n",
      "138691             A great way to learn the months   \n",
      "\n",
      "                                                     Text  \n",
      "138706  this witty little book makes my son laugh at l...  \n",
      "138688  I grew up reading these Sendak books, and watc...  \n",
      "138689  This is a fun way for children to learn their ...  \n",
      "138690  This is a great little book to read aloud- it ...  \n",
      "138691  This is a book of poetry about the months of t...  \n"
     ]
    }
   ],
   "source": [
    "print(finaldata.shape)\n",
    "print(finaldata.ndim)\n",
    "print(finaldata.columns)\n",
    "print(finaldata.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS: \n",
    "    \n",
    "    -> TIME BASED SPLITTING:\n",
    "        \n",
    "        -> Converting the text data to vectors\n",
    "        \n",
    "        -> Using L2 regularization with random search and grid search to determine the \"C\"\n",
    "        \n",
    "        -> Using L1 regularization with random search and grid search to determine the  \"C\"\n",
    "        \n",
    "        -> Checking the sparsity with different values using L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_count_vect = finaldata.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of the time based sliced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138683</th>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417839</th>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346055</th>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417838</th>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId               ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "138706                     0                       0  positive  939340800   \n",
       "138683                     2                       2  positive  940809600   \n",
       "417839                     0                       0  positive  944092800   \n",
       "346055                     1                       2  positive  944438400   \n",
       "417838                     0                       0  positive  946857600   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138706                          EVERY book is educational   \n",
       "138683  This whole series is great way to spend time w...   \n",
       "417839                               Entertainingl Funny!   \n",
       "346055                            A modern day fairy tale   \n",
       "417838                                         FANTASTIC!   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138683  I can remember seeing the show when it aired o...  \n",
       "417839  Beetlejuice is a well written movie ..... ever...  \n",
       "346055  A twist of rumplestiskin captured on film, sta...  \n",
       "417838  Beetlejuice is an excellent and funny movie. K...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_count_vect.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_count_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv_data = cv.fit_transform(sorted_count_vect[\"Text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(364173, 115282)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_data))\n",
    "print(cv_data.shape)\n",
    "print(cv_data.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words:L2 REGULARIZATION WITH GRID SEARCH AND RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = cv_data[0:250000]\n",
    "xtest = cv_data[250000:]\n",
    "ytrain = sorted_count_vect['Score'][0:250000]\n",
    "ytest = sorted_count_vect['Score'][250000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 115282)\n",
      "(114173, 115282)\n",
      "(250000,)\n",
      "(114173,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words:GRID SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242903313392834"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9242903313392834\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C= 0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C= 0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    BAG OF WORDS:\n",
    "        \n",
    "        -> L2 Regularization with Grid Search Results:\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 1\n",
    "            \n",
    "            -> There is no change in the sparsity level when the values of \"C\" = [1,0.1,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words:RANDOM SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 8, 9, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.randint.rvs(0,10,size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([4, 1, 3, 2, 1])}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)\n",
    "log_reg_l2 = LogisticRegression(penalty='l2')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9242903313392834\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9242903313392834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240450894694893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144981738239338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94292"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "    BAG OF WORDS:\n",
    "    \n",
    "        -> By using L2 Regularization with Random Search the best 'C' value = 1\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L2 Regularization for different values 'C' values there is no improvement in the sparsity\n",
    "    \n",
    "        -> All the 'C' values resulted in the same sparsity\n",
    "    \n",
    "        -> By increasing 'C' value we can observe slightly decrement in accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Bag Of Words:L1 REGULARIZATION WITH GRID SEARCH AND RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = cv_data[0:250000]\n",
    "xtest = cv_data[250000:]\n",
    "ytrain = sorted_count_vect['Score'][0:250000]\n",
    "ytest = sorted_count_vect['Score'][250000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 115282)\n",
      "(114173, 115282)\n",
      "(250000,)\n",
      "(114173,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words:GRID SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9232305361162446\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))\n",
    "print(model.best_estimator_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9232743293072793\n",
      "10764\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9206730137598206\n",
      "2208\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979531062510401\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    BAG OF WORDS:\n",
    "        \n",
    "        -> L1 Regularization with Grid Search Results:\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 1\n",
    "            \n",
    "            -> When the value of \"C\" = 1 it resulted in a sparsity of 10764\n",
    "            \n",
    "            -> When the value of \"C\" = 0.1 it resulted in a sparsity of 2208\n",
    "            \n",
    "            -> When the value of \"C\" = 0.01 it resulted in a sparsity of 444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag Of Words:RANDOM SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([3, 3, 4, 1, 4])}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)\n",
    "log_reg_l2 = LogisticRegression(penalty='l1')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9232392947544515\n",
      "10773\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9206905310362344\n",
      "2205\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979531062510401\n",
      "444\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "    BAG OF WORDS:\n",
    "    \n",
    "        -> Implemented logistic regression with L1 Regularization on Bag Of Words with Random Search\n",
    "    \n",
    "        -> Both the methods have returned the best \"C\" value = 1\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L1 Regularization we can observe the change in sparsity level while the value of \"C\" changes\n",
    "    \n",
    "        -> When \"C\" = 1 it resulted with a sparsity of 10773\n",
    "    \n",
    "        -> When \"C\" = 0.1 it resulted with a sparsity of 2205\n",
    "    \n",
    "        -> When \"C\" = 0.01 it resulted with a sparsity of 444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF: \n",
    "    \n",
    "    -> TIME BASED SPLITTING:\n",
    "        \n",
    "        -> Converting the text data to vectors\n",
    "        \n",
    "        -> Using L2 regularization with random search and grid search to determine the \"C\"\n",
    "        \n",
    "        -> Using L1 regularization with random search and grid search to determine the \"C\"\n",
    "        \n",
    "        -> Checking the sparsity with different values using L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_data = finaldata.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_data = tfidf_vect.fit_transform(tfidf_data['Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 2910206)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = tfidf_vect_data[0:250000]\n",
    "xtest = tfidf_vect_data[250000:]\n",
    "ytrain = tfidf_data[\"Score\"][0:250000]\n",
    "ytest = tfidf_data['Score'][250000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 2910206)\n",
      "(250000,)\n",
      "(114173, 2910206)\n",
      "(114173,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF:L2 REGULARIZATION WITH GRID SEARCH AND RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 2910206)\n",
      "(250000,)\n",
      "(114173, 2910206)\n",
      "(114173,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF:GRID SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466598933197866"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n",
    "model.score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933425590989113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2270091"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881180314084766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2270091"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257468928730961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2270091"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    TFIDF:\n",
    "        \n",
    "        -> L2 Regularization with Grid Search Results:\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 100\n",
    "            \n",
    "            -> There is no change in the sparsity level when the values of \"C\" = [1,0.1,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF:RANDOM SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 6, 2, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.randint.rvs(1,10,size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([1, 3, 3, 3, 1])}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l2')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9418514009441812\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933425590989113\n",
      "2270091\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881180314084766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2270091"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257468928730961\n",
      "2270091\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    TFIDF\n",
    "    \n",
    "        -> By using L2 Regularization with  Random Search the best 'C' value = 3\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L2 Regularization for different values 'C' values there is no improvement in the sparsity\n",
    "    \n",
    "        -> All the 'C' values resulted in the same sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF:GRID SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9421842291960446\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9423418846837693\n",
      "127776\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=10000,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9397142932216899\n",
      "2985\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9009923537088453\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827673793278621\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "      TFIDF:\n",
    "        \n",
    "            -> L1 Regularization with Grid Search Results:\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 10000\n",
    "            \n",
    "            -> When the value of \"C\" = 10000 it resulted in a sparsity of 127776\n",
    "            \n",
    "            -> When the value of \"C\" = 1 it resulted in a sparsity of 2985\n",
    "            \n",
    "            -> When the value of \"C\" = 0.1 it resulted in a sparsity of 370\n",
    "            \n",
    "            -> When the value of \"C\" = 0.01 it resulted in a sparsity of 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF:RANDOM SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([3, 1, 3, 3, 2])}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=3, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l1')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9460117540924737\n",
      "10130\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=3,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9397055345834829\n",
      "2987\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9009923537088453\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827673793278621\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "    TFIDF:\n",
    "    \n",
    "        -> Implemented logistic regression with L1 regularization on TFIDF with Random Search\n",
    "    \n",
    "        -> Both the methods have returned the best \"C\" value = 3\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L1 Regularization we can observe the change in sparsity level while the value of \"C\" changes\n",
    "    \n",
    "        -> When \"C\" = 3 it resulted with a sparsity of 10130\n",
    "        \n",
    "        -> When \"C\" = 1 it resulted with a sparsity of 2987\n",
    "    \n",
    "        -> When \"C\" = 0.1 it resulted with a sparsity of 370\n",
    "    \n",
    "        -> When \"C\" = 0.01 it resulted with a sparsity of 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD2VEC:\n",
    "    \n",
    "    Constructing the word2vec representation of each word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanhtml(sentence):\n",
    "    clean = re.compile(\"<.*?>\")\n",
    "    cleantext = re.sub(clean,\" \",sentence)\n",
    "    return cleantext\n",
    "def cleanpunct(sentence):\n",
    "    cleanr = re.sub(r\"[?|!|\\|'|#|.|,|)|(|/]\",r' ',sentence)\n",
    "    return cleanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_w2vec = finaldata.sort_values(\"Time\",axis=0,ascending=True,kind='quicksort',na_position='last',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364173, 10)\n",
      "2\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "            Id   ProductId          UserId               ProfileName  \\\n",
      "138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
      "138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
      "417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
      "346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
      "417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
      "\n",
      "        HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
      "138706                     0                       0  positive  939340800   \n",
      "138683                     2                       2  positive  940809600   \n",
      "417839                     0                       0  positive  944092800   \n",
      "346055                     1                       2  positive  944438400   \n",
      "417838                     0                       0  positive  946857600   \n",
      "\n",
      "                                                  Summary  \\\n",
      "138706                          EVERY book is educational   \n",
      "138683  This whole series is great way to spend time w...   \n",
      "417839                               Entertainingl Funny!   \n",
      "346055                            A modern day fairy tale   \n",
      "417838                                         FANTASTIC!   \n",
      "\n",
      "                                                     Text  \n",
      "138706  this witty little book makes my son laugh at l...  \n",
      "138683  I can remember seeing the show when it aired o...  \n",
      "417839  Beetlejuice is a well written movie ..... ever...  \n",
      "346055  A twist of rumplestiskin captured on film, sta...  \n",
      "417838  Beetlejuice is an excellent and funny movie. K...  \n"
     ]
    }
   ],
   "source": [
    "print(sorted_w2vec.shape)\n",
    "print(sorted_w2vec.ndim)\n",
    "print(sorted_w2vec.columns)\n",
    "print(sorted_w2vec.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "sentences_list=[]\n",
    "for sent in sorted_w2vec['Text'].values:\n",
    "    filtered_sentences = []\n",
    "    sent = cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleanedwords in cleanpunct(w).split():\n",
    "            if(cleanedwords.isalpha()):\n",
    "                filtered_sentences.append(cleanedwords.lower())\n",
    "    sentences_list.append(filtered_sentences)   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364173\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_list))\n",
    "print(type(sentences_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = gensim.models.Word2Vec(sentences_list,min_count=4,size=100,workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Most similar word\n",
    "\n",
    "-> Similarity between the words\n",
    "\n",
    "-> Dimensionality representation of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('when', 0.555910050868988), ('wherever', 0.5385503768920898), ('somewhere', 0.5213028192520142), ('everywhere', 0.517043948173523), ('anywhere', 0.511245846748352), ('why', 0.49936985969543457), ('whenever', 0.4894091486930847), ('what', 0.4891246259212494), ('until', 0.4887976348400116), ('tx', 0.46112507581710815)]\n",
      "0.24810759684835426\n",
      "[-1.1313014   1.0932155   0.11378156  0.5984697  -0.40777805  0.36542675\n",
      " -0.10039888 -0.6144885   0.1795656   0.3624454  -0.22921501  0.19641885\n",
      " -0.2573651   0.9770184  -0.06685726 -0.09147077 -0.00734534 -0.04665074\n",
      " -0.26663142  0.64368945 -0.11834418  0.28151038  0.2889424  -0.21643315\n",
      " -0.1667287  -0.36938614  0.6879662  -0.10011698  0.94558644  0.5527474\n",
      "  0.0572133   0.2621847  -0.18907733  0.66910386 -0.11617593  0.12504373\n",
      "  0.25503594  0.1557429  -0.01187207 -0.54485494 -0.07472737  0.8321764\n",
      "  0.18299055  0.9956394  -0.36131296 -0.05197132  0.72592556  0.25233057\n",
      "  0.45833567 -0.28377217  0.6090648   0.20261562  0.07647496 -0.8056886\n",
      " -0.35348964 -0.06347021 -0.0497982  -0.77958965  0.3941121   0.14914612\n",
      " -0.21553643 -0.20195153  0.036475    0.6339579  -0.00773144 -0.27580798\n",
      " -0.31185317  0.99352306  0.28453943 -0.11844904  0.029054    0.27830666\n",
      " -0.2959344  -0.07851963  0.13070121 -0.17581376 -0.45458436 -0.36290792\n",
      " -0.7638931   0.627594   -0.19319664 -0.04386482 -0.31185874 -0.0699504\n",
      "  0.03932377 -0.17857397  0.24290591  0.4074607  -0.02756741 -0.6117686\n",
      " -0.2612249   0.5490796   0.20474638  0.05279277  0.4699347   0.21727744\n",
      "  0.74875426 -0.68860763  0.5961362   0.41836035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(w2vmodel.most_similar(\"where\"))\n",
    "print(w2vmodel.similarity(\"where\",'who'))\n",
    "print(w2vmodel.wv['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    -> We have constructed the vector representation of each word\n",
    "    \n",
    "    -> Using this model to construct vector representation of each sentence in average word2vec and tfidf-word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC: \n",
    "    \n",
    "    -> TIME BASED SPLITTING:\n",
    "        \n",
    "        -> Converting the text data to vectors with the help of word2vec\n",
    "        \n",
    "        -> Using L2 regularization with random search and grid search to determine the \"C\"\n",
    "        \n",
    "        -> Using L1 regularization with random search and grid search to determine the \"C\"\n",
    "        \n",
    "        -> Checking the sparsity with different values using L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vthumati/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364173\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent_vectors = []\n",
    "for sent in sentences_list: \n",
    "    sent_vec = np.zeros(100) \n",
    "    cnt=0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = w2vmodel.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[88888]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(sent_vectors).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vectors = np.nan_to_num(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 100)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC:L2 REGULARIZATION WITH GRID SEARCH AND RANDOM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = sent_vectors[0:250000]\n",
    "xtest = sent_vectors[250000:]\n",
    "ytrain = sorted_w2vec['Score'][0:250000]\n",
    "ytest = sorted_w2vec['Score'][250000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 100)\n",
      "(114173, 100)\n",
      "(250000,)\n",
      "(114173,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC:GRID SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9422017464724585"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5,n_jobs=4)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n",
    "model.score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8896761931454897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8892995717025917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884762597111401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "    AVERAGE WORD2VEC:\n",
    "        \n",
    "        -> L2 Regularization with Grid Search Results:\n",
    "        \n",
    "            -> Since we constructed the vector representation of each word in 100 dimensions\n",
    "            \n",
    "            -> Now each sentence is also in 100 dimensions\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 10000\n",
    "            \n",
    "            -> There is no change in the sparsity level when the values of \"C\" = [1,0.1,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC:RANDOM SEARCH IMPLEMENTATION FOR L2 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([3, 4, 2, 1, 4])}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l2')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9426221611063912\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8896849517836967\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8892995717025917\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884762597111401\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l2')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "np.count_nonzero(v)\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "  AVERAGE WORD2VEC:\n",
    "    \n",
    "        -> By using L2 Regularization with  Random Search the best 'C' value = 4\n",
    "        \n",
    "        -> Since we constructed the vector representation of each word in 100 dimensions\n",
    "\n",
    "        -> Now each sentence is also in 100 dimensions\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L2 Regularization for different values 'C' values there is no improvement in the sparsity\n",
    "    \n",
    "        -> All the 'C' values resulted in the same sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC:GRID SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9418338836677673\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(log_reg,parameters,scoring='accuracy',cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n",
    "print(model.score(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894747444667304\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893258476172125\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875478440612053\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "     AVERAGE WORD2VEC:\n",
    "        \n",
    "            -> L1 Regularization with Grid Search Results:\n",
    "            \n",
    "            -> Since we constructed the vector representation of each word in 100 dimensions\n",
    "\n",
    "            -> Now each sentence is also in 100 dimensions\n",
    "            \n",
    "            -> The grid search resulted with best \"C\" value as 10000\n",
    "            \n",
    "            -> When the value of \"C\" = 10000 it resulted in a sparsity of 100\n",
    "            \n",
    "            -> When the value of \"C\" = 1 it resulted in a sparsity of 100\n",
    "            \n",
    "            -> When the value of \"C\" = 0.1 it resulted in a sparsity of 96\n",
    "            \n",
    "            -> When the value of \"C\" = 0.01 it resulted in a sparsity of 82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVERAGE WORD2VEC:RANDOM SEARCH IMPLEMENTATION FOR L1 REGULARIZATION CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': array([3, 4, 1, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': scipy.stats.randint.rvs(1,5,size=5)}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg_l2 = LogisticRegression(penalty='l1')\n",
    "model = RandomizedSearchCV(log_reg_l2,param_distributions=param_grid,scoring='accuracy',cv=5,n_iter=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "print(model.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894747444667304\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893170889790055\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.1,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875478440612053\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.01,penalty='l1')\n",
    "clf2.fit(xtrain,ytrain)\n",
    "print(clf2.score(xtest,ytest))\n",
    "v = clf2.coef_\n",
    "print(np.count_nonzero(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "    AVERAGE WORD2VEC:\n",
    "    \n",
    "        -> Implemented logistic regression with L1 regularization on Average word2vec with Random Search\n",
    "        \n",
    "        -> Since we constructed the vector representation of each word in 100 dimensions\n",
    "\n",
    "        -> Now each sentence is also in 100 dimensions\n",
    "    \n",
    "        ->  The best \"C\" value = 4\n",
    "    \n",
    "        -> Experimented different 'C' values to check the sparsity\n",
    "    \n",
    "        -> By using L1 Regularization we can observe the change in sparsity level while the value of \"C\" changes\n",
    "        \n",
    "        -> When \"C\" = 1 it resulted with a sparsity of 100\n",
    "    \n",
    "        -> When \"C\" = 0.1 it resulted with a sparsity of 98\n",
    "    \n",
    "        -> When \"C\" = 0.01 it resulted with a sparsity of 82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "    \n",
    "    -> Grid search and Random search are applied to determine the best hyper parameter\n",
    "    \n",
    "    -> These cross validation techniques can be applied to any estimator\n",
    "    \n",
    "    -> L2 regularization does not provide any sparsity with the different hyper parameter tuning using both grid  \n",
    "    search and Random search\n",
    "        \n",
    "    -> L1 regularization provides sparsity and it increases its sparsity if we tune the hyper parameter\n",
    "    \n",
    "    -> The main reason for providing sparsity in L1 than L2 is due to constant slope in L1   \n",
    "\n",
    "    -> By using sparsity we can neglect the low weighted features\n",
    "    \n",
    "    -> These type of models are very useful in the low latency applications for quick response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
